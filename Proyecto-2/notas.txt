kubectl apply -f crds.yaml ->  crea los crd

kubectl apply -f operator.yaml  -> crea el eck operator en un namespace que se crea solo

helm install databases databases  -> crea el rabbitmq

elasticsearch.yaml  -> crea elasticsearch y kibana cuando hace el helm install de arriba. Hay que ejecutar los comandos de crds.yaml y operator.yaml para crear estos pods

en el producer.yaml y consumer.yaml cambian miguelku por su username de docker

docker login(si no sirve el login desde lens, usen el cmd de windows y ejecutan los comandos ahÃ­)

en la carpeta producer(solo hace build y push, cambia user por su username de docker):
docker build -t user/producer .
docker images
docker -v run user/producer
docker push user/producer
kubectl apply -f producer.yaml

en la carpeta consumer:
docker build -t user/consumer .
docker push user/consumer

kubectl port-forward service/databases-rabbitmq 5672:5672


en el forward de kibana:
GET _cat/indices

GET docidx/_search


// Entrar a la base de datos mariadb
kubectl port-forward databases-mariadb-0 3305:3306

// Enlace del cambio del SSL de mysql workbench
https://stackoverflow.com/questions/69769563/how-do-i-disable-the-ssl-requirement-in-mysql-workbench

// Enlace de tutoriales de rabbitmq
https://www.rabbitmq.com/getstarted.html


docker pull docker.elastic.co/elasticsearch/elasticsearch:8.4.3
docker pull docker.elastic.co/kibana/kibana:8.4.3





mobile app -> escribe un job y el loader escucha a mariadb la tabla job, lo procesa se pega al api de biorxiv
revisa count y total, en el job el grp size, loader saca la info de biorxic y calcula cuantos grupos hacer
offset (grp id 0 con offset de 0, grp id 1 offset 200)

22549/size grupo -> cant grupo(redondea arriba)

downloader -> baja size grupo a es

cada descarga del downloader de los docs, det se mete a es y saca docs, por cada doc, agarra rel_doi y el rel_site en minuscula y la mete en el doc original


no jats